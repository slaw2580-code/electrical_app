

import os, json, uuid, time, math, argparse, re
from dataclasses import dataclass, asdict
from pathlib import Path

import cv2
import numpy as np
from PIL import Image
import requests
from dotenv import load_dotenv
import networkx as nx
from ultralytics import YOLO


# =========================
# â”€â”€ í† í´ë¡œì§€(ë°°ì„  ê·¸ë˜í”„) ì¶”ì¶œ
CANNY1 = 80
CANNY2 = 160
HOUGH_THRESH = 60
HOUGH_MIN_LEN = 30
HOUGH_MAX_GAP = 5
MERGE_TOL = 6            # ë°°ì„  ëì  ë³‘í•© ê±°ë¦¬(px)

# â”€â”€ í† í´ë¡œì§€ ê¸°ë°˜ ë§¤ì¹­
MAX_TEXT_WIRE_DIST = 10  # í…ìŠ¤íŠ¸ ì¤‘ì‹¬ì´ ë°°ì„ (ì„ ë¶„)ê¹Œì§€ â‰¤ ì´ ê±°ë¦¬ì´ë©´ ê·¸ íšŒë¡œ(ì»´í¬ë„ŒíŠ¸)ë¡œ ê·€ì†
SPATIAL_TIE = 80         # ê°™ì€ íšŒë¡œë¼ë„ ì´ ì´ìƒ ë©€ë©´ ë²„ë¦¼(íƒ€ì´ë¸Œë ˆì´ì»¤)
TOPK_PER_SYMBOL = 5

# â”€â”€ ë¡œì»¬ ìœˆë„ìš° í•˜ë“œê²Œì´íŠ¸(í† í´ë¡œì§€ ì‹¤íŒ¨ ì‹œ ë°±ì—…)
LOCAL_PAD_X = 30         # ì‹¬ë³¼ bbox ì¢Œìš° íŒ¨ë”©
LOCAL_PAD_Y = 24         # ì‹¬ë³¼ bbox ìƒí•˜ íŒ¨ë”©
BASE_MAX_DIST = 70       # ì „ì—­ ê±°ë¦¬ ìƒí•œ (ë°±ì—… ëª¨ë“œ)
HARD_MAX = 60            # ì ˆëŒ€ ê±°ë¦¬ ìƒí•œ (ë°±ì—… ëª¨ë“œ)
DIST_PER_SIZE = 0.7
MIN_ALIGN = 0.30
ALIGN_BONUS = 0.8
MIN_EDGE_W = 0.20
REL_MARGIN = 1.07

CLASS_RADIUS_MUL = {"ACB":0.7,"MCCB":0.7,"VCB":0.7,"ELB":0.8,"CT":0.6,"VT":0.6,"TR":0.9,"PF":0.8,"LA":0.7,"MOF":0.8,"PT":0.7}

# â”€â”€ í´ë˜ìŠ¤ë³„ í—ˆìš©/ê¸ˆì§€ í† í°(ë©€ë¦¬ ìˆëŠ” ë‹¤ë¥¸ ì¥ì¹˜ëª… í…ìŠ¤íŠ¸ ì»·)
CLASS_ALLOW = {
    "LA":  ["LA", "KV", "KA", "DISC", "W/DISC"],
    "PF":  ["PF", "KV", "KA", "FUSE", "A"],
    "CT":  ["CT", "/5A", "A", "CL", "N>"],
    "VT":  ["VT", "PT", "V", "KV", "VA"],
    "PT":  ["PT", "V", "KV", "VA", "/"],
    "VCB": ["VCB", "KV", "A", "KA", "MVA"],
    "CB":  ["VCB", "CB", "KV", "A", "KA"],
    "MOF": ["MOF", "PT", "CT", "V", "A"],
}
CLASS_DENY = {
    "LA":  ["MOF","PT","PF","CT","VCB","CB"],
    "PF":  ["MOF","PT","CT","VCB","CB"],
    "CT":  ["MOF","PT","PF","VCB","CB"],
    "PT":  ["MOF","PF","CT","VCB","CB"],
    "VCB": ["MOF","PT","PF","CT"],
    "CB":  ["MOF","PT","PF","CT"],
    "MOF": ["VCB","CB","LA","PF"],
}

# =========================
# ìœ í‹¸
# =========================
def _center(bbox):
    x1, y1, x2, y2 = bbox
    return (0.5*(x1+x2), 0.5*(y1+y2))

def _size(b):
    x1,y1,x2,y2 = b
    return max(1.0, (x2-x1) + (y2-y1))

def _dist(c1, c2):
    dx, dy = (c1[0]-c2[0]), (c1[1]-c2[1])
    return (dx*dx + dy*dy) ** 0.5

def _h_align(sym_box, txt_box):
    sy = 0.5*(sym_box[1]+sym_box[3]); ty = 0.5*(txt_box[1]+txt_box[3])
    scale = max(sym_box[3]-sym_box[1], txt_box[3]-txt_box[1], 1.0)
    return max(0.0, 1.0 - abs(sy-ty)/(2.0*scale))

def _v_align(sym_box, txt_box):
    sx = 0.5*(sym_box[0]+sym_box[2]); tx = 0.5*(txt_box[0]+txt_box[2])
    scale = max(sym_box[2]-sym_box[0], txt_box[2]-txt_box[0], 1.0)
    return max(0.0, 1.0 - abs(sx-tx)/(2.0*scale))

# =========================
# ë°°ì„ (ì „ì„ /ë¦¬ë”ì„ ) ì¶”ì¶œ â†’ ì»´í¬ë„ŒíŠ¸ ê·¸ë˜í”„
# =========================
def _pt_seg_dist(px, py, x1, y1, x2, y2):
    # ì -ì„ ë¶„ ê±°ë¦¬
    vx, vy = x2 - x1, y2 - y1
    wx, wy = px - x1, py - y1
    denom = vx*vx + vy*vy
    if denom <= 1e-6:
        return math.hypot(px-x1, py-y1)
    t = max(0.0, min(1.0, (wx*vx + wy*vy) / denom))
    cx, cy = x1 + t*vx, y1 + t*vy
    return math.hypot(px-cx, py-cy)

def _bbox_intersects_segment(b, x1, y1, x2, y2, pad=2):
    # bboxì™€ ì„ ë¶„ êµì°¨/ê·¼ì ‘ ì—¬ë¶€(íŒ¨ë”©)
    bx1, by1, bx2, by2 = b
    bx1 -= pad; by1 -= pad; bx2 += pad; by2 += pad
    # ë°•ìŠ¤ ì•ˆì— ì„ ë¶„ ëì ì´ ë“¤ì–´ì˜¤ë©´ true
    if (bx1 <= x1 <= bx2 and by1 <= y1 <= by2) or (bx1 <= x2 <= bx2 and by1 <= y2 <= by2):
        return True
    # ë°•ìŠ¤ ì¤‘ì‹¬ê³¼ ì„ ë¶„ ê±°ë¦¬ë¡œ ê·¼ì ‘ íŒì •
    cx, cy = (bx1+bx2)/2, (by1+by2)/2
    w, h = (bx2-bx1), (by2-by1)
    return _pt_seg_dist(cx, cy, x1, y1, x2, y2) <= 0.5*max(w, h)

def _build_wire_components(image_path: Path):
    """
    ì´ë¯¸ì§€ì—ì„œ ë°°ì„ /ë¦¬ë”ì„ ì„ ì¶”ì¶œí•´ endpoint ë³‘í•© ê·¸ë˜í”„ë¥¼ ë§Œë“ ë‹¤.
    ê±°ì˜ ìˆ˜í‰/ìˆ˜ì§(Â±10ë„) ì„ ë¶„ë§Œ ì±„íƒ.
    ë°˜í™˜: segs(list[(x1,y1,x2,y2)]), seg_indexâ†’comp_id dict, point-graph WG
    """
    img = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)
    if img is None:
        return [], {}, nx.Graph()
    edges = cv2.Canny(img, CANNY1, CANNY2)
    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=HOUGH_THRESH,
                            minLineLength=HOUGH_MIN_LEN, maxLineGap=HOUGH_MAX_GAP)
    segs = []
    if lines is not None:
        for l in lines[:,0,:]:
            x1,y1,x2,y2 = map(int, l)
            ang = abs(math.degrees(math.atan2(y2-y1, x2-x1)))
            if (ang < 10) or (ang > 80):  # 0Â±10Â° or 90Â±10Â°
                segs.append((x1,y1,x2,y2))

    # ëì  ë³‘í•© ê·¸ë˜í”„
    WG = nx.Graph()
    def _near(p,q,t=MERGE_TOL): return math.hypot(p[0]-q[0], p[1]-q[1]) <= t
    pts = []
    for (x1,y1,x2,y2) in segs:
        p1 = (x1,y1); p2 = (x2,y2)
        f1 = next((i for i,p in enumerate(pts) if _near(p,p1)), None)
        f2 = next((i for i,p in enumerate(pts) if _near(p,p2)), None)
        if f1 is None: pts.append(p1); f1 = len(pts)-1
        if f2 is None: pts.append(p2); f2 = len(pts)-1
        WG.add_node(f1, xy=pts[f1]); WG.add_node(f2, xy=pts[f2])
        WG.add_edge(f1, f2)

    comp = {}
    if WG.number_of_nodes() > 0:
        comps = list(nx.connected_components(WG))
        # ì»´í¬ë„ŒíŠ¸ ID í• ë‹¹(ì–‘ ëì ì´ ë™ì¼ ì»´í¬ë„ŒíŠ¸ì— ìˆìœ¼ë©´ ê·¸ ì„ ë¶„ì€ ê·¸ ì»´í¬ë„ŒíŠ¸ ì†Œì†)
        for cid, nodes in enumerate(comps):
            nodes = list(nodes); node_set = set(nodes)
            for idx,(x1,y1,x2,y2) in enumerate(segs):
                # ê°€ì¥ ê°€ê¹Œìš´ ë…¸ë“œ ì°¾ê¸°
                def _closest_node(x,y):
                    best = None; bd = 1e9
                    for n in nodes:
                        nx_, ny_ = WG.nodes[n]['xy']
                        d = (nx_-x)**2 + (ny_-y)**2
                        if d < bd: bd = d; best = n
                    return best
                n1 = _closest_node(x1,y1); n2 = _closest_node(x2,y2)
                if (n1 in node_set) and (n2 in node_set):
                    comp[idx] = cid
    return segs, comp, WG

# =========================
# í† í´ë¡œì§€ ìš°ì„  ë§¤ì¹­ + ë¡œì»¬ ìœˆë„ìš° ë°±ì—…
# =========================
def _class_token_ok(text, cls):
    t  = (text or "").upper()
    c  = (cls or "").upper()
    allow = CLASS_ALLOW.get(c, ["V","KV","A","KA","HZ","P"])
    deny  = CLASS_DENY.get(c, [])
    if any(d in t for d in deny):
        return False
    return any(a in t for a in allow)

def _inside_local_window(sym_box, txt_box):
    sx1,sy1,sx2,sy2 = sym_box
    cx, cy = _center(txt_box)
    return (sx1-LOCAL_PAD_X) <= cx <= (sx2+LOCAL_PAD_X) and (sy1-LOCAL_PAD_Y) <= cy <= (sy2+LOCAL_PAD_Y)

def _adaptive_radius(sym_class, sym_box, cli_max):
    base = min(max(cli_max, 40), BASE_MAX_DIST)
    rad  = base + DIST_PER_SIZE * _size(sym_box)
    mul  = CLASS_RADIUS_MUL.get(str(sym_class).upper(), 1.0)
    return max(30.0, min(rad * mul, min(BASE_MAX_DIST, HARD_MAX)))

def match_symbols_with_texts_graph_TOPOFIRST(detected_symbols, ocr_results, image_path: Path,
                                             cli_max_link=120):
    """
    1) ì´ë¯¸ì§€ì—ì„œ ë°°ì„  ê·¸ë˜í”„ ì»´í¬ë„ŒíŠ¸ ìƒì„±
    2) 'ê°™ì€ íšŒë¡œ' í…ìŠ¤íŠ¸ë§Œ í›„ë³´(1ìˆœìœ„)
    3) íšŒë¡œê°€ ë¶ˆëª…í™•í•˜ë©´ ë¡œì»¬ ìœˆë„ìš° í•˜ë“œê²Œì´íŠ¸ + ê±°ë¦¬/ì •ë ¬ë¡œ ë°±ì—…
    """
    segs, comp_map, WG = _build_wire_components(image_path)

    # â”€â”€ ì‹¬ë³¼ â†’ comp ì§‘í•©
    sym_comp_sets = []
    for s in detected_symbols:
        comps = set()
        for idx,(x1,y1,x2,y2) in enumerate(segs):
            if _bbox_intersects_segment(s["bbox"], x1,y1,x2,y2, pad=2):
                cid = comp_map.get(idx)
                if cid is not None:
                    comps.add(cid)
        sym_comp_sets.append(comps)

    # â”€â”€ í…ìŠ¤íŠ¸ â†’ comp (ë°°ì„ ì— ê°€ê¹Œìš´ ì„ ë¶„ì˜ comp)
    txt_comp = []
    for t in ocr_results:
        cx, cy = _center(t["bbox"])
        best_d = 1e9; best_c = None
        for idx,(x1,y1,x2,y2) in enumerate(segs):
            d = _pt_seg_dist(cx, cy, x1,y1,x2,y2)
            if d < best_d:
                best_d = d; best_c = comp_map.get(idx)
        txt_comp.append(best_c if best_d <= MAX_TEXT_WIRE_DIST else None)

    # â”€â”€ í›„ë³´ ì„ íƒ
    for i, s in enumerate(detected_symbols):
        sym_cls = s.get("class","")
        cand = []

        # [A] ê°™ì€ íšŒë¡œ í…ìŠ¤íŠ¸
        if sym_comp_sets[i]:
            scx, scy = _center(s["bbox"])
            for j, t in enumerate(ocr_results):
                c = txt_comp[j]
                if (c is None) or (c not in sym_comp_sets[i]):  # ë‹¤ë¥¸ íšŒë¡œë©´ ì œì™¸
                    continue
                if not _class_token_ok(t.get("text"), sym_cls):
                    continue
                tcx, tcy = _center(t["bbox"])
                d = math.hypot(scx-tcx, scy-tcy)
                if d > SPATIAL_TIE:
                    continue
                cand.append((j, d, 1.0/(1.0+d)))  # ê°™ì€ íšŒë¡œë©´ weightëŠ” ê±°ë¦¬ íƒ€ì´ë¸Œë ˆì´ì»¤ë§Œ

        # [B] íšŒë¡œê°€ ë¹„ì–´ ìˆê±°ë‚˜ í›„ë³´ê°€ 0ì´ë©´ â†’ ë¡œì»¬ ìœˆë„ìš° ë°±ì—…
        if not cand:
            rad = _adaptive_radius(sym_cls, s["bbox"], cli_max_link)
            for j, t in enumerate(ocr_results):
                txt = (t.get("text") or "").strip()
                if not txt or not _class_token_ok(txt, sym_cls):
                    continue
                if not _inside_local_window(s["bbox"], t["bbox"]):
                    continue
                ha = _h_align(s["bbox"], t["bbox"]); va = _v_align(s["bbox"], t["bbox"])
                if max(ha,va) < MIN_ALIGN:
                    continue
                d = _dist(_center(s["bbox"]), _center(t["bbox"]))
                if d > rad:
                    continue
                decay = math.exp(-d / max(1.0, rad*0.6))
                w = decay * (1.0 + ALIGN_BONUS*max(ha, va))
                if w < MIN_EDGE_W:
                    continue
                cand.append((j, d, w))

        # ì •ë¦¬ + topK
        cand.sort(key=lambda x: (-x[2], x[1]))  # weight ë‚´ë¦¼ì°¨ìˆœ, ê±°ë¦¬ ì˜¤ë¦„ì°¨ìˆœ
        chosen = []
        for j, d, w in cand[:TOPK_PER_SYMBOL]:
            t = ocr_results[j]
            chosen.append({
                "text": (t.get("text") or "").strip(),
                "bbox": t["bbox"],
                "distance": round(float(d), 2),
                "weight": round(float(w), 4)
            })
        s["ocr_texts"] = chosen

    return detected_symbols

# =========================
# ì‹¬ë³¼ë³„ ì†ì„± íŒŒì‹±
# =========================
VOLTAGE_RE = re.compile(r"\b(\d+(?:\.\d+)?)\s*(k?V)\b", re.I)  # 22kV, 380V
CURRENT_RE = re.compile(r"\b(\d+(?:\.\d+)?)\s*A\b", re.I)      # 630A
ICAP_RE    = re.compile(r"\b(\d+(?:\.\d+)?)\s*kA\b", re.I)     # 5kA
POLES_RE   = re.compile(r"\b(\d)\s*P\b", re.I)                 # 3P, 4P
FREQ_RE    = re.compile(r"\b(\d+(?:\.\d+)?)\s*Hz\b", re.I)     # 60Hz
KIND_RE    = re.compile(r"\b(ACB|MCCB|VCB|GCB|ELB|VC)\b", re.I)

def _norm(text: str) -> str:
    return (text or "").replace("4P600V","4P 600V").replace("P600V","P 600V")

def parse_attrs(text: str) -> dict:
    t = _norm(text)
    out = {}
    if m := KIND_RE.search(t):     out["kind"] = m.group(1).upper()
    if m := VOLTAGE_RE.search(t):  out["rated_voltage"] = f"{m.group(1)}{m.group(2).upper()}"
    if m := CURRENT_RE.search(t):  out["rated_current"] = f"{m.group(1)}A"
    if m := ICAP_RE.search(t):     out["breaking_capacity"] = f"{m.group(1)}kA"
    if m := POLES_RE.search(t):    out["poles"] = f"{m.group(1)}P"
    if m := FREQ_RE.search(t):     out["frequency"] = f"{m.group(1)}Hz"
    return out

def attach_symbol_attributes(detected_symbols: list) -> list:
    for s in detected_symbols:
        texts = s.get("ocr_texts", [])
        per_text = []
        merged = {}
        for t in texts:
            txt = (t.get("text") or "").strip()
            if not txt:
                continue
            parsed = parse_attrs(txt)
            per_text.append({"text": txt, "parsed": parsed})
            for k, v in parsed.items():
                merged.setdefault(k, v)
        s["text_parsed"] = per_text
        s["attributes"]  = merged
    return detected_symbols

# =========================
# í™˜ê²½ë³€ìˆ˜
# =========================
env_path = Path(__file__).resolve().parent / ".env"
load_dotenv(dotenv_path=str(env_path))
OCR_SECRET_KEY = os.getenv("CLOVA_OCR_SECRET_KEY")
OCR_API_URL    = os.getenv("CLOVA_OCR_URL")

print("OCR_SECRET_KEY =", (OCR_SECRET_KEY or "None")[:6], "...")
print("OCR_API_URL    =", (OCR_API_URL or "None")[:30], "...")
if not OCR_SECRET_KEY or not OCR_API_URL:
    raise RuntimeError("í™˜ê²½ë³€ìˆ˜(.env)ì— CLOVA_OCR_SECRET_KEY / CLOVA_OCR_URLì„ ì„¤ì •í•˜ì„¸ìš”.")

# =========================
# OCR / YOLO
# =========================
def run_clova_ocr(image_path: Path):
    req_json = {
        'images': [{'format': 'jpg', 'name': 'demo'}],
        'requestId': str(uuid.uuid4()),
        'version': 'V2',
        'timestamp': int(round(time.time() * 1000))
    }
    payload = {'message': json.dumps(req_json).encode('UTF-8')}
    headers = {'X-OCR-SECRET': OCR_SECRET_KEY}
    with open(str(image_path), 'rb') as f:
        files_payload = [('file', f)]
        resp = requests.post(OCR_API_URL, headers=headers, data=payload, files=files_payload, timeout=60)
    resp.raise_for_status()

    ocr_results = []
    ocr_data = resp.json()
    for image_result in ocr_data.get('images', []):
        for field in image_result.get('fields', []):
            text = field.get('inferText', '')
            vertices = field.get('boundingPoly', {}).get('vertices', [])
            if len(vertices) >= 3:
                x1, y1 = vertices[0]['x'], vertices[0]['y']
                x2, y2 = vertices[2]['x'], vertices[2]['y']
                ocr_results.append({'text': text, 'bbox': [x1, y1, x2, y2]})
    return ocr_results

def run_yolo_detect(image_path: Path, weights_path: Path):
    model = YOLO(str(weights_path))
    img_pil = Image.open(str(image_path)).convert("RGB")
    img = np.array(img_pil)
    img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)

    results = model(img_bgr)
    print(results[0].verbose())

    detected_symbols = []
    for *box, conf, cls in results[0].boxes.data:
        x1, y1, x2, y2 = map(int, box)
        class_name = model.names[int(cls)]
        print(f"ğŸ”¹ {class_name} | bbox=({x1},{y1})~({x2},{y2}) | conf={float(conf):.2f}")
        detected_symbols.append({
            'class': class_name,
            'bbox': [x1, y1, x2, y2],
            'confidence': float(conf),
            'ocr_texts': []
        })
    return detected_symbols

# =========================
# ìš”ì•½ íŒì •(ë°ëª¨)
# =========================
@dataclass
class BreakerInfo:
    kind: str|None = None
    rated_voltage: str|None = None
    rated_current: str|None = None
    breaking_capacity: str|None = None

BREAKER_KIND_RE = r'\b(ACB|MCCB|VCB|GCB|ELB)\b'
VOLT_RE         = r'(\d{3,4})\s*V\b'
AMP_RE          = r'(\d{2,4})\s*A\b'
KA_RE           = r'(\d{1,3})\s*kA\b'

def parse_breaker_from_text(text: str) -> BreakerInfo:
    text = text.replace('P600V', 'P 600V').replace('4P600V','4P 600V')
    info = BreakerInfo()
    if m:=re.search(BREAKER_KIND_RE, text, re.I): info.kind = m.group(1).upper()
    if m:=re.search(VOLT_RE, text, re.I):         info.rated_voltage = m.group(1)+'V'
    if m:=re.search(AMP_RE, text, re.I):          info.rated_current = m.group(1)+'A'
    if m:=re.search(KA_RE, text, re.I):           info.breaking_capacity = m.group(1)+'kA'
    return info

def validate_breaker(info: BreakerInfo):
    missing = []
    if not info.kind:              missing.append("ì¢…ë¥˜")
    if not info.rated_voltage:     missing.append("ì •ê²©ì „ì••")
    if not info.rated_current:     missing.append("ì •ê²©ì „ë¥˜")
    if not info.breaking_capacity: missing.append("ì •ê²©ì°¨ë‹¨ì „ë¥˜")
    return {"all_present": len(missing)==0, "missing": missing, "extracted": asdict(info)}

# =========================
# ë©”ì¸
# =========================
def main():
    parser = argparse.ArgumentParser(description="YOLO + CLOVA OCR (ë¡œì»¬) â†’ final_result.json / final_summary.json")
    parser.add_argument("--image", required=True, help="ë„ë©´ ì´ë¯¸ì§€ ê²½ë¡œ (jpg/png)")
    parser.add_argument("--weights", required=True, help="YOLO ê°€ì¤‘ì¹˜ ê²½ë¡œ (ì˜ˆ: data/models/best.pt)")
    parser.add_argument("--out", default="final_result.json", help="ì¶œë ¥ JSON ê²½ë¡œ")
    parser.add_argument("--dist_thr", type=int, default=30, help="(ë°±ì—…ëª¨ë“œ) ê·¸ë˜í”„ ì—£ì§€ ìµœëŒ€ ê±°ë¦¬(px) í•˜í•œì„ ")
    args = parser.parse_args()

    image_path = Path(args.image)
    weights_path = Path(args.weights)
    output_json_path = Path(args.out)

    if not image_path.exists():
        raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
    if not weights_path.exists():
        raise FileNotFoundError(f"YOLO ê°€ì¤‘ì¹˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {weights_path}")

    # 1) YOLO
    detected_symbols = run_yolo_detect(image_path, weights_path)

    # 2) OCR (ì˜ˆì™¸ ë°©ì–´: ì‹¤íŒ¨í•´ë„ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì§„í–‰í•´ JSON ìƒì„± ë³´ì¥)
    print("CLOVA OCR í˜¸ì¶œ ì¤‘...")
    try:
        ocr_results = run_clova_ocr(image_path)
        print(f"OCR í…ìŠ¤íŠ¸ ê°œìˆ˜: {len(ocr_results)}")
    except Exception as e:
        print("[ê²½ê³ ] OCR ì‹¤íŒ¨ -> ë¹ˆ ê²°ê³¼ë¡œ ì§„í–‰:", e)
        ocr_results = []

    # 3) í† í´ë¡œì§€ ìš°ì„  ë§¤ì¹­ (ê°™ì€ íšŒë¡œë§Œ í›„ë³´)
    print("í† í´ë¡œì§€ ê¸°ë°˜ ë§¤ì¹­ ìˆ˜í–‰.")
    detected_symbols = match_symbols_with_texts_graph_TOPOFIRST(
        detected_symbols,
        ocr_results,
        image_path=image_path,
        cli_max_link=max(args.dist_thr, 60)  # ë°±ì—…ëª¨ë“œì—ì„œ ì“°ì¼ ìƒí•œ í•˜í•œ
    )

    # 3.5) ì‹¬ë³¼ë³„ ì†ì„± ë¶€ì°©
    detected_symbols = attach_symbol_attributes(detected_symbols)

    # 4) ê²°ê³¼ ì €ì¥(final_result.json)
    with open(output_json_path, "w", encoding="utf-8") as f:
        json.dump(detected_symbols, f, indent=4, ensure_ascii=False)
    print(f"[ì €ì¥] {output_json_path.resolve()}")

    # 5) ì „ì²´ í…ìŠ¤íŠ¸ ê¸°ë°˜ 1ì°¨ ìš”ì•½íŒì •(final_summary.json) â€” ë°ëª¨
    all_ocr_texts = []
    for s in detected_symbols:
        for t in s.get("ocr_texts", []):
            if txt := (t.get("text") or "").strip():
                all_ocr_texts.append(txt)
    flat_text = " ".join(all_ocr_texts)
    bi = parse_breaker_from_text(flat_text)
    judge = validate_breaker(bi)
    summary_path = output_json_path.with_name("final_summary.json")
    with open(summary_path, "w", encoding="utf-8") as f:
        json.dump(judge, f, indent=4, ensure_ascii=False)
    print("[ìš”ì•½íŒì •]", judge)
    print(f"[ì €ì¥] {summary_path.resolve()}")

    # 6) ì½˜ì†” ìš”ì•½(ì‹¬ë³¼ ë‹¨ìœ„ ì—°ê²° í™•ì¸ìš©)
    for symbol in detected_symbols:
        cls = symbol.get("class", "UNKNOWN")
        texts = [t["text"] for t in symbol.get("ocr_texts", []) if (t.get("text") or "").strip()]
        attrs = symbol.get("attributes", {})
        if texts:
            joined = '", "'.join(texts)
            print(f'[{cls}] ê·¼ì²˜ í…ìŠ¤íŠ¸: "{joined}"  -> attributes={attrs}')
        else:
            print(f'[{cls}] ê·¼ì²˜ í…ìŠ¤íŠ¸: ì—†ìŒ  -> attributes={attrs}')

if __name__ == "__main__":
    main()
